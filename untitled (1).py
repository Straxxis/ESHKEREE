# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c4nq2D8YYNUTL7xgmZQk5xW3hf3-5QES
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy import stats

from google.colab import files
uploaded = files.upload()

df = pd.read_csv(open('income.csv', 'rb'))
df.head()

df

for column in df.columns:
  print(f'колонка: {column}')

df.info()

# Проверка на пропущенные значения
print(df.isnull().sum())

np.random.seed(42)
df_test_nan = df.copy()
df_test_nan.loc[np.random.choice(df_test_nan.index, size=5, replace=True), 'education'] = np.nan
print(df_test_nan.isnull().sum()) # пропусков нет

# Вариант 1: Удаление строк с пропусками
df_drop = df_test_nan.dropna()
print("\n# Удаление строк с пропусками")
print(df_drop.isnull().sum()) # пропусков нет

# Вариант 2: Заполнение пропусков медианой
df_median = df_test_nan.copy()
df_median.age = df_median.age.fillna(df_median.age.median())

print("\n# Заполнение пропусков медианой")
print(df_median.isnull().sum()) # пропусков нет

# Вариант 3: Заполнение пропусков средним
df_mean = df_test_nan.copy()
df_mean.age = df_mean.age.fillna(df_median.age.mean())

print("\n# Заполнение пропусков средним")
print(df_mean.isnull().sum()) # пропусков нет

df['old_employers'] = np.where(df['age'] >= 50, 1, 0).astype(int)
df.columns

Y = df['old_employers'] # выбираем целевую переменную
X = df.drop('old_employers', axis=1) # переменные для проверки влияния
X = X.drop('age', axis=1)

# Список числовых колонок для построения графиков
numeric_cols = X.select_dtypes(include=['float64', 'int64'])
numeric_cols

# Построение boxplot для каждой переменной
for col in numeric_cols:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x='old_employers', y=col, data=df)
    plt.title(f'Boxplot {col} относительно old_employers')
    plt.show()

# Построение диаграмм распределения для каждой переменной
for col in numeric_cols:
    plt.figure(figsize=(8, 6))
    sns.histplot(data=df, x=col, hue='old_employers', element="step", stat="density", common_norm=False)
    plt.title(f'Распределение {col} относительно old_employers')
    plt.show()

"""⏰График "Распределение education-num": На этом графике видно, что уровень образования оказывает влияние на целевой признак. Большинство наблюдений сосредоточено в диапазоне от 8 до 10 для обеих категорий старых работодателей. Люди с уровнем образования выше 10 имеют более высокую вероятность наличия прежнего работодателя. Это также указывает на то, что с увеличением уровня образования возрастает вероятность получения высоких доходов, что может быть важным для анализа целевой переменной.

График "Распределение capital-gain": Здесь наблюдается, что большинство значений капитальных приростов (capital gain) сосредоточено на нуле. Однако те, у кого есть положительные значения, могут значительно влиять на целевой признак (доход >50K). Наличие небольшого количества таких наблюдений имеет важное значение.

График "Распределение capital-loss": Ситуация с потерями капитала аналогична: большинство наблюдений также сосредоточено около нуля, но наличие небольших выбросов может указывать на различия в целевом признаке.

График "Распределение hours-per-week": Большинство людей работают около 40 часов в неделю, но есть и те, кто работает меньше или больше. Это может быть важным индикатором для предсказания дохода, так как те, кто работает более 40 часов, могут иметь большую вероятность получения дохода выше 50K.

График "Распределение income >50K": Наблюдения с доходом выше 50K чаще встречаются среди тех, кто имел прежнего работодателя, что может свидетельствовать о влиянии опыта и карьерного роста на уровень дохода.
"""

# Описательная статистика для числовых переменных, разделенная по целевой переменной
desc_stats_numeric = df.groupby('old_employers')[df.select_dtypes(include=[np.number]).columns].describe()

# Описательная статистика для категориальных переменных, разделенная по целевой переменной
desc_stats_categorical = df.groupby('old_employers')[df.select_dtypes(include=['object']).columns].describe()

# Проходим по каждой числовой переменной и выводим статистику отдельно
for col in numeric_cols:
    print(f"Описательная статистика для {col}:\n")
    print(df.groupby('old_employers')[col].describe())
    print("\n" + "="*50 + "\n")

print("\nКатегориальные переменные:")
desc_stats_categorical

"""Age: Средний возраст в группе с old_employers = 0 (младше 50 лет) составляет 33.03 года, с разбросом (стандартное отклонение) 8.95. Минимальный возраст — 17, максимальный — 49. В группе с old_employers = 1 (старше 50 лет) средний возраст составляет 58.62 года, с меньшим стандартным отклонением 7.48. Возраст варьируется от 50 до 90 лет.


Education-num: У людей младше 50 лет среднее количество лет образования равно 10.15, в то время как у людей старше 50 лет это значение чуть ниже — 9.83. Диапазон значений в обеих группах схож: от 1 до 16 лет образования.
Income >50K: Среди людей младше 50 лет медианное значение переменной income

>50K равно 0 (большинство зарабатывают меньше 50K). Среди людей старше 50 лет медианное значение переменной — 1, что указывает на то, что значительное число людей в этой группе зарабатывают больше 50K.


Workclass (категориальная переменная): В обеих возрастных группах большинство людей работают в частном секторе: Private. В группе old_employers = 0 — 18,735 человек работают в частном секторе, в группе old_employers = 1 — 3,961.


Education (категориальная переменная): В обеих группах наиболее частое образование — HS-grad (средняя школа): у 8,090 человек в группе младше 50 лет и 2,411 человек в группе старше 50 лет.


Marital-status: В группе младше 50 лет самым частым семейным статусом является Never-married (8090 человек), в группе старше 50 лет — Married-civ-spouse (2411 человек).


Race: В обеих группах преобладают представители White (белые): 21,607 человек среди младше 50 лет и 6,209 среди старше 50 лет.


Sex: Среди людей младше 50 лет 16,776 человек — мужчины, среди старше 50 лет 5,014 — мужчины.


Native-country: В обеих группах большинство людей родом из United-States: 22,761 среди младше 50 лет и 6,409 среди старше 50 лет.
"""



df[df.select_dtypes(include=[np.number]).columns].corr()

"""Описание корреляций для значимых признаков: Age и Old_employers (0.773): Очень высокая положительная корреляция между возрастом и переменной old_employers. Это логично, так как переменная old_employers напрямую основана на возрасте — она указывает, старше ли человек 50 лет. Этот признак напрямую связан с целевой переменной и не может использоваться для прогноза других переменных. Education-num и Income >50K (0.335): Есть умеренная положительная корреляция между количеством лет образования и доходом более 50K. Это указывает на то, что более образованные люди чаще зарабатывают больше. Этот признак может быть важным для прогнозирования уровня дохода. Capital-gain и Income >50K (0.223): Наблюдается положительная корреляция между приростом капитала и доходом более 50K. Это означает, что люди с приростом капитала чаще имеют более высокий доход. Hours-per-week и Income >50K (0.230): Умеренная корреляция между количеством рабочих часов в неделю и доходом. Больше рабочих часов коррелирует с более высоким доходом, что вполне ожидаемо. Income >50K и Old_employers (0.115): Есть слабая положительная корреляция между переменной income >50K и возрастом свыше 50 лет. Это указывает на то, что более старшие работники немного чаще зарабатывают больше."""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Выбираем категориальные признаки
categorical_features = X.select_dtypes(include=['object', 'int64']).columns.tolist()

print("Категориальные признаки:", categorical_features)

# Создаем копию данных
X_processed = X.copy()

# Применяем One-Hot Encoding
X_processed = pd.get_dummies(X_processed, columns=categorical_features, drop_first=True) # drop_first=True позволяет избежать мультиколлинеарности, удаляя первый уровень категориальной переменной.

X_processed

# Выбираем числовые признаки
numeric_features = X_processed.select_dtypes(include=['int64']).columns.tolist()

print("Числовые признаки:", numeric_features)

# Инициализируем scaler
scaler = MinMaxScaler()

def train_and_evaluate(X, Y):
    # Разделение данных на обучающую и тестовую выборки
    X_train, X_test, Y_train, Y_test = train_test_split(
        X, Y, test_size=0.2, random_state=42, stratify=Y)

    # Инициализация модели
    model = LogisticRegression(max_iter=1000)

    # Обучение модели
    model.fit(X_train, Y_train)

    # Предсказания на обучающей выборке
    Y_train_pred = model.predict(X_train)
    train_accuracy = accuracy_score(Y_train, Y_train_pred)

    # Предсказания на тестовой выборке
    Y_test_pred = model.predict(X_test)
    test_accuracy = accuracy_score(Y_test, Y_test_pred)

    # Вывод результатов
    print(f"Точность на обучающей выборке: {train_accuracy:.4f}")
    print(f"Точность на тестовой выборке: {test_accuracy:.4f}")

    # Классификационный отчет
    print("\nКлассификационный отчет на тестовой выборке:")
    print(classification_report(Y_test, Y_test_pred))

    return model

# Обучение модели
model = train_and_evaluate(X_processed, Y)

# Получение коэффициентов модели
coefficients = pd.DataFrame({
    'Feature': X_processed.columns,
    'Coefficient': model.coef_[0]
})

# Сортировка по абсолютному значению коэффициента
coefficients['Abs_Coefficient'] = coefficients['Coefficient'].abs()
coefficients = coefficients.sort_values(by='Abs_Coefficient', ascending=False)

print(coefficients[['Feature', 'Coefficient']])

"""Кросс-валидация модели"""

from sklearn.model_selection import cross_val_score

# Кросс-валидация с 5 фолдами
scores = cross_val_score(model, X_processed, Y, cv=5, scoring='accuracy')

print(f"Средняя точность при кросс-валидации: {scores.mean():.4f}")
print(f"Отклонение точности: {scores.std():.4f}")

X_train, X_test, Y_train, Y_test = train_test_split(X_processed, Y, test_size=0.2, random_state=42, stratify=Y)

from sklearn.metrics import roc_curve, auc

# Предсказания вероятностей для тестовой выборки
Y_test_prob = model.predict_proba(X_test)[:, 1]

# Расчет ROC-кривой
fpr, tpr, thresholds = roc_curve(Y_test, Y_test_prob)
roc_auc = auc(fpr, tpr)

# Построение графика
plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0,1], [0,1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-кривая')
plt.legend(loc='lower right')
plt.show()